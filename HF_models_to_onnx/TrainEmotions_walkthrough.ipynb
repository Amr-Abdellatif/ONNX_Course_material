{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itanOMBN5EWg",
        "outputId": "11658d90-b3c3-4f84-e1e7-20fa61c8e2c0"
      },
      "outputs": [],
      "source": [
        "# %pip install datasets==2.18.0 transformers onnx onnxruntime -q\n",
        "# !pip install accelerate -U\n",
        "# !pip install transformers[torch]\n",
        "# !pip install onnx=1.16.1 # 1.16.1 to avoid dll error\n",
        "# !pip install onnxruntime"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HqlT_xzmz2gt"
      },
      "source": [
        "We use the small distilled BERT model from Microsoft as our pre-trained model which we fine-tune on the emotion classification task.\n",
        "See https://huggingface.co/microsoft/xtremedistil-l6-h256-uncased for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kg76LB_ey0Zi"
      },
      "outputs": [],
      "source": [
        "model_name = 'microsoft/xtremedistil-l6-h256-uncased'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "42449d3ac4b94f7ea5feb81c5fc8c89c",
            "86665ae790ae45a1939b8ee021b5cef1",
            "503b3e6a94664677a9f99c1805933911",
            "b64380e6068c4db7afd83581cce46e6d",
            "e3d34e735e34494480f5fe549a4cd574",
            "210adde0f5384335a061de8c2eeeba73",
            "9a045e4afaf3435c841e473bcdc50c32",
            "60ef77aaf04f4663883393fb73145f3a",
            "9ea679d0f33b449f8eefc4d92ec664c1",
            "0522a031b78c4f2b8905871ced2d1b4a",
            "70d9d14f19e64551976d255030357981"
          ]
        },
        "id": "olHJ-ItY5R6t",
        "outputId": "d887e3cc-1b20-478e-d327-5aec96e11eee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Amr osama abdellatif\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#laod the dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"emotion\")\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "#Initialize a Pretrained Tokenizer:\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    This function takes as input a batch of examples (usually in dictionary format) and tokenizes the \"text\" field of each example.\n",
        "    padding=\"max_length\" ensures that all tokenized sequences are padded to the maximum length (128 tokens in this case).\n",
        "    truncation=True ensures that text sequences longer than the maximum length (128) are truncated.\n",
        "    max_length=128 sets the maximum length for tokenized sequences.\n",
        "    \"\"\"\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "LpBYSTs15h27"
      },
      "outputs": [],
      "source": [
        "full_train_dataset = tokenized_datasets[\"train\"]\n",
        "full_eval_dataset = tokenized_datasets[\"test\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbT3wxcL6qen",
        "outputId": "abbafc83-2dae-4cfa-afe2-6bb1d8b87423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1pOQHBh5l6l",
        "outputId": "3c790852-2f5c-475c-e7ba-aa1fed85a97c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/xtremedistil-l6-h256-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "# load a pre-trained model for sequence classification from Hugging Face \n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBCo1LY17sYS",
        "outputId": "db5fb086-2558-4394-e27f-87e92c0fa677"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Temp\\ipykernel_8416\\722645183.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"accuracy\")\n",
            "c:\\Users\\Amr osama abdellatif\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/accuracy/accuracy.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "# make a fn to compare logits to labels\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S8AryVRy6xb5"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "training_args = TrainingArguments(output_dir=\"test_trainer\",\n",
        "                                  per_device_train_batch_size=128,\n",
        "                                  num_train_epochs=1,learning_rate=3e-05,\n",
        "                                  eval_strategy=\"epoch\")\n",
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=full_train_dataset,\n",
        "    eval_dataset=full_eval_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "uXHzn8CH53Hh",
        "outputId": "b3720b08-f6ea-47b4-a6fa-9f5509ed303f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                 \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125/125 [02:43<00:00,  1.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.4835593700408936, 'eval_accuracy': 0.583, 'eval_runtime': 14.8081, 'eval_samples_per_second': 135.062, 'eval_steps_per_second': 16.883, 'epoch': 1.0}\n",
            "{'train_runtime': 163.1689, 'train_samples_per_second': 98.058, 'train_steps_per_second': 0.766, 'train_loss': 1.607395751953125, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=125, training_loss=1.607395751953125, metrics={'train_runtime': 163.1689, 'train_samples_per_second': 98.058, 'train_steps_per_second': 0.766, 'total_flos': 59061116928000.0, 'train_loss': 1.607395751953125, 'epoch': 1.0})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "VC_x9_-p8LmO",
        "outputId": "495d91eb-2822-46e3-ac24-30c02f0dcb12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/250 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [00:04<00:00, 56.65it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.440544605255127,\n",
              " 'eval_accuracy': 0.59,\n",
              " 'eval_runtime': 4.4392,\n",
              " 'eval_samples_per_second': 450.531,\n",
              " 'eval_steps_per_second': 56.316,\n",
              " 'epoch': 1.0}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.evaluate()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "hdTnHS5Ma0Hc"
      },
      "source": [
        "Export PyTorch model to ONNX format for serving with ONNX Runtime Web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gw5w-O0YCpbm"
      },
      "outputs": [],
      "source": [
        "import transformers\n",
        "import transformers.convert_graph_to_onnx as onnx_convert\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "e46GMI9FGYV_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
          ]
        }
      ],
      "source": [
        "pipeline = transformers.pipeline(\"text-classification\",model=model,tokenizer=tokenizer,device='cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KT-lBe5hHD0U"
      },
      "outputs": [],
      "source": [
        "model = model.to(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbYsOZheCwTu",
        "outputId": "a92d763d-75aa-4c09-d34e-3e190045533e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using framework PyTorch: 2.4.0+cu118\n",
            "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found output output_0 with shape: {0: 'batch'}\n",
            "Ensuring inputs are in correct order\n",
            "position_ids is not present in the generated input list.\n",
            "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"
          ]
        }
      ],
      "source": [
        "onnx_convert.convert_pytorch(pipeline, opset=14, output=Path(\"classifier.onnx\"), use_external_format=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB_nkkDQ7OO2",
        "outputId": "5247b10b-3668-4d70-d37e-3e978d62b12e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Amr osama abdellatif\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
            "  warnings.warn(\n",
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        }
      ],
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "quantize_dynamic(\"classifier.onnx\", \"classifier_int8.onnx\",\n",
        "                 weight_type=QuantType.QUInt8)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KyLlyMMoa-E9"
      },
      "source": [
        "Evaluate accuracy using ONNX-Runtime inference - validate PyTorch inference versus ONNX-Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "64GP3FbC3Puz"
      },
      "outputs": [],
      "source": [
        "import onnxruntime as ort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ojSj8awa3Rd6"
      },
      "outputs": [],
      "source": [
        "session = ort.InferenceSession(\"classifier.onnx\")\n",
        "session_int8 = ort.InferenceSession(\"classifier_int8.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OeLLbPWl36Xt"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vRM83eOd3Y7M"
      },
      "outputs": [],
      "source": [
        "input_feed = {\n",
        "    \"input_ids\": np.array(full_eval_dataset['input_ids']),\n",
        "    \"attention_mask\": np.array(full_eval_dataset['attention_mask']),\n",
        "    \"token_type_ids\": np.array(full_eval_dataset['token_type_ids'])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Assuming input_feed is a dictionary with the inputs lets convert them into int64\n",
        "input_feed_converted = {key: np.array(value, dtype=np.int64) for key, value in input_feed.items()}\n",
        "\n",
        "# Run the sessions with the converted inputs\n",
        "out = session.run(input_feed=input_feed_converted, output_names=['output_0'])[0]\n",
        "out_int8 = session_int8.run(input_feed=input_feed_converted, output_names=['output_0'])[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1w5QMJSm4GW1"
      },
      "outputs": [],
      "source": [
        "# out = session.run(input_feed=input_feed_converted,output_names=['output_0'])[0]\n",
        "# out_int8 = session_int8.run(input_feed=input_feed_converted,output_names=['output_0'])[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "YC9E5iIu4W4U"
      },
      "outputs": [],
      "source": [
        "predictions = np.argmax(out, axis=-1)\n",
        "predictions_int8 = np.argmax(out_int8, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W3LmHcyK4ndB",
        "outputId": "0efcd183-77b1-4185-af2c-5791d492e5ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.59}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=predictions, references=full_eval_dataset['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FznKYHhb56Dv",
        "outputId": "aade6fb8-ca9b-47df-cb8c-74c151a9cc2a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.575}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metric.compute(predictions=predictions_int8, references=full_eval_dataset['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TrainEmotions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0522a031b78c4f2b8905871ced2d1b4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "210adde0f5384335a061de8c2eeeba73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42449d3ac4b94f7ea5feb81c5fc8c89c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86665ae790ae45a1939b8ee021b5cef1",
              "IPY_MODEL_503b3e6a94664677a9f99c1805933911",
              "IPY_MODEL_b64380e6068c4db7afd83581cce46e6d"
            ],
            "layout": "IPY_MODEL_e3d34e735e34494480f5fe549a4cd574"
          }
        },
        "503b3e6a94664677a9f99c1805933911": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60ef77aaf04f4663883393fb73145f3a",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ea679d0f33b449f8eefc4d92ec664c1",
            "value": 2000
          }
        },
        "60ef77aaf04f4663883393fb73145f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d9d14f19e64551976d255030357981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86665ae790ae45a1939b8ee021b5cef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210adde0f5384335a061de8c2eeeba73",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_9a045e4afaf3435c841e473bcdc50c32",
            "value": "Map:â€‡100%"
          }
        },
        "9a045e4afaf3435c841e473bcdc50c32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ea679d0f33b449f8eefc4d92ec664c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b64380e6068c4db7afd83581cce46e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0522a031b78c4f2b8905871ced2d1b4a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_70d9d14f19e64551976d255030357981",
            "value": "â€‡2000/2000â€‡[00:00&lt;00:00,â€‡3333.44â€‡examples/s]"
          }
        },
        "e3d34e735e34494480f5fe549a4cd574": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
