{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Amr osama abdellatif\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 - 0s - loss: 1.0806 - accuracy: 0.4667 - 463ms/epoch - 19ms/step\n",
      "Epoch 2/50\n",
      "24/24 - 0s - loss: 0.8418 - accuracy: 0.7333 - 26ms/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "24/24 - 0s - loss: 0.7190 - accuracy: 0.9417 - 25ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "24/24 - 0s - loss: 0.6483 - accuracy: 0.8750 - 25ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "24/24 - 0s - loss: 0.5977 - accuracy: 0.8167 - 22ms/epoch - 917us/step\n",
      "Epoch 6/50\n",
      "24/24 - 0s - loss: 0.5517 - accuracy: 0.8833 - 22ms/epoch - 917us/step\n",
      "Epoch 7/50\n",
      "24/24 - 0s - loss: 0.5110 - accuracy: 0.9167 - 19ms/epoch - 792us/step\n",
      "Epoch 8/50\n",
      "24/24 - 0s - loss: 0.4774 - accuracy: 0.9250 - 19ms/epoch - 792us/step\n",
      "Epoch 9/50\n",
      "24/24 - 0s - loss: 0.4489 - accuracy: 0.9167 - 19ms/epoch - 792us/step\n",
      "Epoch 10/50\n",
      "24/24 - 0s - loss: 0.4241 - accuracy: 0.9333 - 21ms/epoch - 875us/step\n",
      "Epoch 11/50\n",
      "24/24 - 0s - loss: 0.4019 - accuracy: 0.9333 - 19ms/epoch - 792us/step\n",
      "Epoch 12/50\n",
      "24/24 - 0s - loss: 0.3894 - accuracy: 0.8750 - 19ms/epoch - 792us/step\n",
      "Epoch 13/50\n",
      "24/24 - 0s - loss: 0.3628 - accuracy: 0.9667 - 19ms/epoch - 791us/step\n",
      "Epoch 14/50\n",
      "24/24 - 0s - loss: 0.3455 - accuracy: 0.9583 - 17ms/epoch - 708us/step\n",
      "Epoch 15/50\n",
      "24/24 - 0s - loss: 0.3307 - accuracy: 0.9583 - 18ms/epoch - 751us/step\n",
      "Epoch 16/50\n",
      "24/24 - 0s - loss: 0.3162 - accuracy: 0.9667 - 18ms/epoch - 751us/step\n",
      "Epoch 17/50\n",
      "24/24 - 0s - loss: 0.3031 - accuracy: 0.9500 - 19ms/epoch - 792us/step\n",
      "Epoch 18/50\n",
      "24/24 - 0s - loss: 0.2856 - accuracy: 0.9500 - 20ms/epoch - 833us/step\n",
      "Epoch 19/50\n",
      "24/24 - 0s - loss: 0.2762 - accuracy: 0.9583 - 17ms/epoch - 709us/step\n",
      "Epoch 20/50\n",
      "24/24 - 0s - loss: 0.2571 - accuracy: 0.9750 - 19ms/epoch - 792us/step\n",
      "Epoch 21/50\n",
      "24/24 - 0s - loss: 0.2391 - accuracy: 0.9583 - 23ms/epoch - 957us/step\n",
      "Epoch 22/50\n",
      "24/24 - 0s - loss: 0.2270 - accuracy: 0.9667 - 21ms/epoch - 876us/step\n",
      "Epoch 23/50\n",
      "24/24 - 0s - loss: 0.2122 - accuracy: 0.9750 - 18ms/epoch - 751us/step\n",
      "Epoch 24/50\n",
      "24/24 - 0s - loss: 0.2043 - accuracy: 0.9833 - 19ms/epoch - 792us/step\n",
      "Epoch 25/50\n",
      "24/24 - 0s - loss: 0.1991 - accuracy: 0.9583 - 18ms/epoch - 750us/step\n",
      "Epoch 26/50\n",
      "24/24 - 0s - loss: 0.1856 - accuracy: 0.9750 - 18ms/epoch - 751us/step\n",
      "Epoch 27/50\n",
      "24/24 - 0s - loss: 0.1793 - accuracy: 0.9833 - 18ms/epoch - 750us/step\n",
      "Epoch 28/50\n",
      "24/24 - 0s - loss: 0.1723 - accuracy: 0.9833 - 17ms/epoch - 708us/step\n",
      "Epoch 29/50\n",
      "24/24 - 0s - loss: 0.1641 - accuracy: 0.9833 - 17ms/epoch - 708us/step\n",
      "Epoch 30/50\n",
      "24/24 - 0s - loss: 0.1582 - accuracy: 0.9833 - 20ms/epoch - 833us/step\n",
      "Epoch 31/50\n",
      "24/24 - 0s - loss: 0.1519 - accuracy: 0.9750 - 19ms/epoch - 792us/step\n",
      "Epoch 32/50\n",
      "24/24 - 0s - loss: 0.1468 - accuracy: 0.9750 - 17ms/epoch - 708us/step\n",
      "Epoch 33/50\n",
      "24/24 - 0s - loss: 0.1448 - accuracy: 0.9667 - 18ms/epoch - 751us/step\n",
      "Epoch 34/50\n",
      "24/24 - 0s - loss: 0.1395 - accuracy: 0.9750 - 17ms/epoch - 708us/step\n",
      "Epoch 35/50\n",
      "24/24 - 0s - loss: 0.1344 - accuracy: 0.9833 - 21ms/epoch - 875us/step\n",
      "Epoch 36/50\n",
      "24/24 - 0s - loss: 0.1350 - accuracy: 0.9667 - 17ms/epoch - 708us/step\n",
      "Epoch 37/50\n",
      "24/24 - 0s - loss: 0.1278 - accuracy: 0.9750 - 16ms/epoch - 667us/step\n",
      "Epoch 38/50\n",
      "24/24 - 0s - loss: 0.1299 - accuracy: 0.9667 - 54ms/epoch - 2ms/step\n",
      "Epoch 39/50\n",
      "24/24 - 0s - loss: 0.1270 - accuracy: 0.9667 - 19ms/epoch - 792us/step\n",
      "Epoch 40/50\n",
      "24/24 - 0s - loss: 0.1193 - accuracy: 0.9833 - 16ms/epoch - 667us/step\n",
      "Epoch 41/50\n",
      "24/24 - 0s - loss: 0.1158 - accuracy: 0.9833 - 16ms/epoch - 667us/step\n",
      "Epoch 42/50\n",
      "24/24 - 0s - loss: 0.1141 - accuracy: 0.9750 - 15ms/epoch - 625us/step\n",
      "Epoch 43/50\n",
      "24/24 - 0s - loss: 0.1156 - accuracy: 0.9833 - 16ms/epoch - 667us/step\n",
      "Epoch 44/50\n",
      "24/24 - 0s - loss: 0.1083 - accuracy: 0.9833 - 16ms/epoch - 667us/step\n",
      "Epoch 45/50\n",
      "24/24 - 0s - loss: 0.1110 - accuracy: 0.9750 - 16ms/epoch - 667us/step\n",
      "Epoch 46/50\n",
      "24/24 - 0s - loss: 0.1051 - accuracy: 0.9833 - 16ms/epoch - 667us/step\n",
      "Epoch 47/50\n",
      "24/24 - 0s - loss: 0.1030 - accuracy: 0.9833 - 16ms/epoch - 667us/step\n",
      "Epoch 48/50\n",
      "24/24 - 0s - loss: 0.1012 - accuracy: 0.9833 - 15ms/epoch - 625us/step\n",
      "Epoch 49/50\n",
      "24/24 - 0s - loss: 0.0994 - accuracy: 0.9750 - 16ms/epoch - 667us/step\n",
      "Epoch 50/50\n",
      "24/24 - 0s - loss: 0.1047 - accuracy: 0.9833 - 17ms/epoch - 708us/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001A2335F3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x000001A2335F3490> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 0s - loss: 0.1297 - accuracy: 0.9667 - 83ms/epoch - 83ms/step\n",
      "Test Accuracy: 0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./output/iris_model_tf\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./output/iris_model_tf\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow model saved to ./output/iris_model_tf\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Training a Simple Model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Load and prepare the dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target.reshape(-1, 1)\n",
    "\n",
    "# One-hot encode the target variable\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=5, verbose=2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Save the model in TensorFlow format\n",
    "tf_model_path = './output/iris_model_tf'\n",
    "model.save(tf_model_path)\n",
    "print(f'TensorFlow model saved to {tf_model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./output/iris_model.onnx\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Conversion to ONNX\n",
    "\n",
    "import tf2onnx\n",
    "import onnx\n",
    "\n",
    "# Define the model path\n",
    "onnx_model_path = './output/iris_model.onnx'\n",
    "\n",
    "# Convert the TensorFlow model to ONNX\n",
    "spec = (tf.TensorSpec((None, X_train.shape[1]), tf.float32, name=\"input\"),)\n",
    "output_path = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13, output_path=onnx_model_path)\n",
    "\n",
    "print(f'Model saved to {onnx_model_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Accuracy: 0.9667\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Inference\n",
    "\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare the input data for inference\n",
    "def prepare_input(data):\n",
    "    return {onnx_model.get_inputs()[0].name: data.astype(np.float32)}\n",
    "\n",
    "# Make predictions\n",
    "input_data = prepare_input(X_test)\n",
    "predictions = onnx_model.run(None, input_data)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = np.argmax(predictions[0], axis=1)\n",
    "true_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(predicted_labels == true_labels)\n",
    "print(f'Inference Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [2 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Section 3: Inference\n",
    "\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# Load the ONNX model\n",
    "onnx_model = ort.InferenceSession(onnx_model_path)\n",
    "\n",
    "# Prepare the input data for inference\n",
    "data = np.array([[4.5, 4.9, 5.1, 5.4],\n",
    "                 [1.5, 2.9, 3.1, 1.4],\n",
    "                 [7.5, 6.9, 8.1, 6.4]])\n",
    "\n",
    "def prepare_input(data):\n",
    "    return {onnx_model.get_inputs()[0].name: data.astype(np.float32)}\n",
    "\n",
    "# Make predictions\n",
    "input_data = prepare_input(data)\n",
    "predictions = onnx_model.run(None, input_data)\n",
    "\n",
    "# Convert the predictions to class labels\n",
    "predicted_labels = np.argmax(predictions[0], axis=1)\n",
    "print(f'Predicted labels: {predicted_labels}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
